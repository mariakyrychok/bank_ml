{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.\n",
    "\n",
    "Постройте модель с предельно большим значением F1-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте F1-меру на тестовой выборке самостоятельно.\n",
    "\n",
    "Дополнительно измеряйте AUC-ROC, сравнивайте её значение с F1-мерой."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Откройте и изучите файл"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [
    {
     "data": {
      "text/plain": "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n0          1    15634602  Hargrave          619    France  Female   42   \n1          2    15647311      Hill          608     Spain  Female   41   \n2          3    15619304      Onio          502    France  Female   42   \n3          4    15701354      Boni          699    France  Female   39   \n4          5    15737888  Mitchell          850     Spain  Female   43   \n\n   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n0     2.0       0.00              1          1               1   \n1     1.0   83807.86              1          0               1   \n2     8.0  159660.80              3          1               0   \n3     1.0       0.00              2          0               0   \n4     2.0  125510.82              1          1               1   \n\n   EstimatedSalary  Exited  \n0        101348.88       1  \n1        112542.58       0  \n2        113931.57       1  \n3         93826.63       0  \n4         79084.10       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowNumber</th>\n      <th>CustomerId</th>\n      <th>Surname</th>\n      <th>CreditScore</th>\n      <th>Geography</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>15634602</td>\n      <td>Hargrave</td>\n      <td>619</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2.0</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>15647311</td>\n      <td>Hill</td>\n      <td>608</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1.0</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>15619304</td>\n      <td>Onio</td>\n      <td>502</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8.0</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>15701354</td>\n      <td>Boni</td>\n      <td>699</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>15737888</td>\n      <td>Mitchell</td>\n      <td>850</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2.0</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/Churn.csv')\n",
    "display(df.head())\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В данных 10000 объектов и 14 признаков (`Exited` - целевой признак). Каждый объект в наборе данных — это информация о поведении клиентов и расторжении договоров с банком. Известно:\n",
    "\n",
    "- *RowNumber* — индекс строки в данных\n",
    "- *CustomerId* — уникальный идентификатор клиента\n",
    "- *Surname* — фамилия\n",
    "- *CreditScore* — кредитный рейтинг\n",
    "- *Geography* — страна проживания\n",
    "- *Gender* — пол\n",
    "- *Age* — возраст\n",
    "- *Tenure* — сколько лет человек является клиентом банка\n",
    "- *Balance* — баланс на счёте\n",
    "- *NumOfProducts* — количество продуктов банка, используемых клиентом\n",
    "- *HasCrCard* — наличие кредитной карты\n",
    "- *IsActiveMember* — активность клиента\n",
    "- *EstimatedSalary* — предполагаемая зарплата\n",
    "- *Exited* — факт ухода клиента\n",
    "\n",
    "В столбце `Tenure` 9% пропусков. В названиях всех колонок видно нарушение стиля. Чтобы двигаться дальше, нужно устранить проблемы в данных."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Подготовка данных"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Стиль заголовков\n",
    "Переименуем столбцы:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [],
   "source": [
    "df.columns = ['row_number', 'customer_id', 'surname', 'credit_score', 'geography', 'gender', 'age', 'tenure', 'balance', 'num_of_products', 'has_cr_card', 'is_active_member', 'estimated_salary', 'excited']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Обработка пропусков\n",
    "\n",
    "Скорее всего, пробелы в столбце `tenure` сигнализируют о том, что этот пользователь недавно стал клиентом банка. Поэтому заполним эти пропуска нулем:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [],
   "source": [
    "df['tenure'] = df['tenure'].fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Бесполезные данные\n",
    "\n",
    "В нашей таблице есть данные, не имеющие потенциальной связи с результатом работы. Эти данные не только полезны для модели, но могут навредить. Поэтому мы избавимся от таких столбцов, как `row_number`, `customer_id`, `surname`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [],
   "source": [
    "df = df.drop(['row_number', 'customer_id', 'surname'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Прямое кодирование (OHE)\n",
    "\n",
    "Наши данные содержат категориальные признаки `geography`, `gender`. Чтобы не возникло ошибки при обучении модели, преобразуем категориальные признаки в численные с помощью техники прямого кодирования (One-Hot Encoding, OHE), а чтобы не попасть в дамми-ловушку вызовом функции `pd.get_dummies()` с аргументом `drop_first`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Приведем все названия столбцов к нижнему регистру:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Разбиение данных на выборки\n",
    "\n",
    "Для того чтобы выполнять задачу классификации нам сначала необходимо разбить данные на три выборки: обучающую, валидационную и тестовую. Разобьем исходные данные в соотношении 3:1:1. Для начала используем метод `train_test_split`, чтобы отделить обучающую выборку от данных. После этого этим же методом разделим оставшиеся данные на две выборки - валидационную и тестовую."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.4, random_state=12345)\n",
    "df_test, df_valid = train_test_split(df_test, test_size=0.5, random_state=12345)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для каждого набора данных выделим целевой признак (`target`) и другие признаки (`features`)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [],
   "source": [
    "def get_features_and_target(data):\n",
    "    return data.drop('excited', axis=1), data['excited']\n",
    "\n",
    "features_train, target_train = get_features_and_target(df_train)\n",
    "\n",
    "features_valid, target_valid = get_features_and_target(df_valid)\n",
    "\n",
    "features_test, target_test = get_features_and_target(df_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Масштабирование признаков\n",
    "\n",
    "Чтобы избежать ловушки, когда алгоритм решит, что один признак важнее другого, признаки масштабируются — приводятся к одному масштабу. Стандартизируем признаки с помощью `StandardScaler`.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "data": {
      "text/plain": "      credit_score       age    tenure   balance  num_of_products  \\\n7041     -2.226392 -0.088482 -0.825373 -1.233163         0.830152   \n5709     -0.087120  0.006422  1.426375 -1.233163        -0.891560   \n7117     -0.917905 -0.752805  0.139662  0.722307        -0.891560   \n7775     -0.253277  0.101325  1.748053 -1.233163         0.830152   \n8735      0.785204 -0.847708  1.748053  0.615625        -0.891560   \n\n      has_cr_card  is_active_member  estimated_salary  geography_germany  \\\n7041            1                 0          0.647083                  0   \n5709            1                 0         -1.658410                  0   \n7117            1                 1         -1.369334                  0   \n7775            1                 0          0.075086                  0   \n8735            0                 1         -1.070919                  0   \n\n      geography_spain  gender_male  \n7041                0            1  \n5709                0            0  \n7117                1            1  \n7775                1            1  \n8735                0            1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>credit_score</th>\n      <th>age</th>\n      <th>tenure</th>\n      <th>balance</th>\n      <th>num_of_products</th>\n      <th>has_cr_card</th>\n      <th>is_active_member</th>\n      <th>estimated_salary</th>\n      <th>geography_germany</th>\n      <th>geography_spain</th>\n      <th>gender_male</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7041</th>\n      <td>-2.226392</td>\n      <td>-0.088482</td>\n      <td>-0.825373</td>\n      <td>-1.233163</td>\n      <td>0.830152</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.647083</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5709</th>\n      <td>-0.087120</td>\n      <td>0.006422</td>\n      <td>1.426375</td>\n      <td>-1.233163</td>\n      <td>-0.891560</td>\n      <td>1</td>\n      <td>0</td>\n      <td>-1.658410</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7117</th>\n      <td>-0.917905</td>\n      <td>-0.752805</td>\n      <td>0.139662</td>\n      <td>0.722307</td>\n      <td>-0.891560</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-1.369334</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7775</th>\n      <td>-0.253277</td>\n      <td>0.101325</td>\n      <td>1.748053</td>\n      <td>-1.233163</td>\n      <td>0.830152</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.075086</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8735</th>\n      <td>0.785204</td>\n      <td>-0.847708</td>\n      <td>1.748053</td>\n      <td>0.615625</td>\n      <td>-0.891560</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-1.070919</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric = ['credit_score', 'age', 'tenure', 'balance', 'num_of_products', 'estimated_salary']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])\n",
    "\n",
    "features_valid.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Баланс классов\n",
    "Посмотрим, сбалансированы ли наши классы в данных"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [
    {
     "data": {
      "text/plain": "0    0.7963\n1    0.2037\nName: excited, dtype: float64"
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['excited'].value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В нашей задаче наблюдается сильный дисбаланс классов (4:1), что плохо скажется на обучении модели. Чтобы выровнять баланс, мы можем использовать такие техники, как: *взвешивание классов*, *upsampling* и *downsampling*. Но будем следовать очередности задач в проекте, и для начала научим модель на несбалансированных данных."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Подготовка прототипа решения"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Наш целевой признак – категоральный, это значит, что мы имеем дело с задачей классификации, а именно *бинарной классификации*, так как категорий всего две («клиет ушел» — `exited = 1`, «клиент остался» — `exited = 0`).\n",
    "\n",
    "Для решения этой задачи нам подойдут следующие модели:\n",
    "- дерево решений;\n",
    "- случайный лес;\n",
    "- логистическую регрессию.\n",
    "\n",
    "Будем поочередно обучать три модели, а затем оценим их.\n",
    "\n",
    "Сначала будем учить модель дерева решений. Для того чтобы получить максимально высокий уровень качества предсказаний, переберем в алгоритме обучения разные варианты глубины дерева от 1 до 30.\n",
    "\n",
    "Так как в данных наблюдается дисбаланс классов, в качестве метрики для оценки качества всех моделей, мы будет использовать не *accuracy*, а *F1-score* (среднее гармоническое *precision* и *recall*)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 наилучшей модели дерева решений на валидационной выборке: 0.5378. \n",
      "Глубина дерева: 9\n"
     ]
    }
   ],
   "source": [
    "random_state = 12345\n",
    "\n",
    "def decision_tree(features_train, target_train, features_valid, target_valid, class_weight=None):\n",
    "    best_model = None\n",
    "    best_result = 0\n",
    "    best_depth = 1\n",
    "\n",
    "    for depth in range(1, 30, 1):\n",
    "        model = DecisionTreeClassifier(random_state=random_state, max_depth=depth, class_weight=class_weight)\n",
    "        model.fit(features_train, target_train)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        result = f1_score(target_valid, predicted_valid)\n",
    "        if result > best_result:\n",
    "            best_model = model\n",
    "            best_depth = depth\n",
    "            best_result = result\n",
    "    return best_result, best_depth, best_model\n",
    "\n",
    "decision_tree_result, decision_tree_depth, _ = decision_tree(\n",
    "    features_train,\n",
    "    target_train,\n",
    "    features_valid,\n",
    "    target_valid\n",
    ")\n",
    "\n",
    "print(f'F1 наилучшей модели дерева решений на валидационной выборке: {decision_tree_result:.4}. ',\n",
    "      f'Глубина дерева: {decision_tree_depth}', sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Модель с лучшим значением *F1-score* (0.5378) на валидационной выборке оказалась модель с глубиной дерева 9. Это не очень хороший результат, но следует помнить, что мы не учли дисбаланс классов.\n",
    "\n",
    "Попробуем натренировать модель случайного леса. Чтобы найти лучшую модель будем подбирать еще один гиперпараметр – количество деревьев (n_estimators) от 10 до 100 с шагом 10."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 наилучшей модели случайного леса на валидационной выборке: 0.5531\n",
      "Количество деревьев: 50\n",
      "Глубина дерева: 18\n"
     ]
    }
   ],
   "source": [
    "def random_forest(features_train, target_train, features_valid, target_valid, class_weight=None):\n",
    "    best_model = None\n",
    "    best_result = 0\n",
    "    best_est = 10\n",
    "    best_depth = 1\n",
    "\n",
    "    for est in range(10, 100, 10):\n",
    "        for depth in range(1, 30, 1):\n",
    "            model = RandomForestClassifier(\n",
    "                random_state=random_state,\n",
    "                n_estimators=est,\n",
    "                max_depth=depth,\n",
    "                class_weight=class_weight\n",
    "            )\n",
    "            model.fit(features_train, target_train)\n",
    "            predicted_valid = model.predict(features_valid)\n",
    "            result = f1_score(target_valid, predicted_valid)\n",
    "            if result > best_result:\n",
    "                best_model = model\n",
    "                best_result = result\n",
    "                best_est = est\n",
    "                best_depth = depth\n",
    "    return best_result, best_est, best_depth, best_model\n",
    "\n",
    "forest_result, forest_est, forest_depth, _ = random_forest(\n",
    "    features_train,\n",
    "    target_train,\n",
    "    features_valid,\n",
    "    target_valid\n",
    ")\n",
    "\n",
    "print(f'F1 наилучшей модели случайного леса на валидационной выборке: {forest_result:.4}',\n",
    "      f'Количество деревьев: {forest_est}',\n",
    "      f'Глубина дерева: {forest_depth}', sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Моделью с лучшим значением *F1-score* (0.5531) на валидационной выборке оказалась модель с количеством деревьев 50, и глубиной - 18. Как видим, *F1-score* модели случайного леса немного выше чем модели дерева решений, но этого значение нам все равно недостаточно для приемлемого результата. Также можно выделить минус модели случайного дерева – скорость выполнения: чем больше древ, тем неторопливее работает модель.\n",
    "\n",
    "Посмотрим какой результат *F1-score* даст модель логистической регрессии на несбалансированных классах."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели логистической регрессии на валидационной выборке: 0.2743\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression(features_train, target_train, features_valid, target_valid, class_weight=None):\n",
    "    model = LogisticRegression(random_state=random_state, solver='liblinear', class_weight=class_weight)\n",
    "    model.fit(features_train, target_train)\n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    result = f1_score(target_valid,predicted_valid)\n",
    "    return result, model\n",
    "\n",
    "logistic_regression_result, _ = logistic_regression(\n",
    "    features_train,\n",
    "    target_train,\n",
    "    features_valid,\n",
    "    target_valid\n",
    ")\n",
    "\n",
    "print(f'F1 модели логистической регрессии на валидационной выборке: {logistic_regression_result:.4}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Среди трех моделей значение *F1-score* наименьшее у логистической регрессии - 0.2743.\n",
    "\n",
    "Но давайте перейдем к балансировке классов, возможно на сбалансированных данных эта модель покажет лучший результат."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Борьба с дисбалансом\n",
    "\n",
    "Как мы уже решили раньше, чтобы выровнять баланс, мы можем использовать такие техники, как: *взвешивание классов*, *upsampling* и *downsampling*. Начнем работу с первого метода - *взвешивание классов*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Взвешивание классов\n",
    "\n",
    "Если указать в параметрах наших алгоритмов *class_weight='balanced'*, алгоритм посчитает, во сколько раз класс «0» встречается чаще класса «1». Обозначим это число N и новые классы будуть выглядят так:\n",
    "- вес класса «0» = 1.0\n",
    "- вес класса «1» = N"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели логистической регрессии на валидационной выборке: 0.4797\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_result, _ = logistic_regression(\n",
    "    features_train,\n",
    "    target_train,\n",
    "    features_valid,\n",
    "    target_valid,\n",
    "    'balanced'\n",
    ")\n",
    "print(f'F1 модели логистической регрессии на валидационной выборке: {logistic_regression_result:.4}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 наилучшей модели случайного леса на валидационной выборке: 0.6197\n",
      "Количество деревьев: 70\n",
      "Глубина дерева: 9\n"
     ]
    }
   ],
   "source": [
    "forest_result, forest_est, forest_depth, _ = random_forest(\n",
    "    features_train,\n",
    "    target_train,\n",
    "    features_valid,\n",
    "    target_valid,\n",
    "    'balanced'\n",
    ")\n",
    "\n",
    "print(f'F1 наилучшей модели случайного леса на валидационной выборке: {forest_result:.4}',\n",
    "      f'Количество деревьев: {forest_est}',\n",
    "      f'Глубина дерева: {forest_depth}', sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 наилучшей модели дерева решений на валидационной выборке: 0.5809. \n",
      "Глубина дерева: 5\n"
     ]
    }
   ],
   "source": [
    "decision_tree_result, decision_tree_depth, _ = decision_tree(\n",
    "    features_train,\n",
    "    target_train,\n",
    "    features_valid,\n",
    "    target_valid,\n",
    "    'balanced'\n",
    ")\n",
    "\n",
    "print(f'F1 наилучшей модели дерева решений на валидационной выборке: {decision_tree_result:.4}. ',\n",
    "      f'Глубина дерева: {decision_tree_depth}', sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Вывод**\n",
    "Взвешивание классов помогло нам добиться неплохого результата. Среди трех алгоритмов можно выделить RandomForest, моделька с количеством деревьев 70 и глубиной дерева 9 дала нам *f1-score* - 0.6197"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Увеличение выборки (upsampling)\n",
    "Редкий класс будем повторять несколько раз (в нашей случаи 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели логистической регрессии на валидационной выборке: 0.4779\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_result, _ = logistic_regression(\n",
    "    features_upsampled,\n",
    "    target_upsampled,\n",
    "    features_valid,\n",
    "    target_valid\n",
    ")\n",
    "print(f'F1 модели логистической регрессии на валидационной выборке: {logistic_regression_result:.4}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 наилучшей модели дерева решений на валидационной выборке: 0.5809. \n",
      "Глубина дерева: 5\n"
     ]
    }
   ],
   "source": [
    "decision_tree_result, decision_tree_depth, _ = decision_tree(\n",
    "    features_upsampled,\n",
    "    target_upsampled,\n",
    "    features_valid,\n",
    "    target_valid\n",
    ")\n",
    "\n",
    "print(f'F1 наилучшей модели дерева решений на валидационной выборке: {decision_tree_result:.4}. ',\n",
    "      f'Глубина дерева: {decision_tree_depth}', sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 наилучшей модели случайного леса на валидационной выборке: 0.6206\n",
      "Количество деревьев: 30\n",
      "Глубина дерева: 11\n"
     ]
    }
   ],
   "source": [
    "forest_result, forest_est, forest_depth, _ = random_forest(\n",
    "    features_upsampled,\n",
    "    target_upsampled,\n",
    "    features_valid,\n",
    "    target_valid\n",
    ")\n",
    "\n",
    "print(f'F1 наилучшей модели случайного леса на валидационной выборке: {forest_result:.4}',\n",
    "      f'Количество деревьев: {forest_est}',\n",
    "      f'Глубина дерева: {forest_depth}', sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Вывод**\n",
    "Продублировав объекты малого класса 4 раза, мы сбалансировали классы. Это помогло достичь *F1-score* - 0.6206 (Модель случайного леса с количеством деревьев 30 и глубиной - 11)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Уменьшение выборки (downsampling)\n",
    "Вместо повторения редкого класса (1), уберём часть класса 0."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=random_state)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=random_state)] + [target_ones])\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=random_state)\n",
    "\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели логистической регрессии на валидационной выборке: 0.4863\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_result, _ = logistic_regression(\n",
    "    features_downsampled,\n",
    "    target_downsampled,\n",
    "    features_valid,\n",
    "    target_valid\n",
    ")\n",
    "print(f'F1 модели логистической регрессии на валидационной выборке: {logistic_regression_result:.4}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 наилучшей модели дерева решений на валидационной выборке: 0.6074. \n",
      "Глубина дерева: 5\n"
     ]
    }
   ],
   "source": [
    "decision_tree_result, decision_tree_depth, _ = decision_tree(\n",
    "    features_downsampled,\n",
    "    target_downsampled,\n",
    "    features_valid,\n",
    "    target_valid\n",
    ")\n",
    "\n",
    "print(f'F1 наилучшей модели дерева решений на валидационной выборке: {decision_tree_result:.4}. ',\n",
    "      f'Глубина дерева: {decision_tree_depth}', sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 наилучшей модели случайного леса на валидационной выборке: 0.5906\n",
      "Количество деревьев: 10\n",
      "Глубина дерева: 5\n"
     ]
    }
   ],
   "source": [
    "forest_result, forest_est, forest_depth, _ = random_forest(\n",
    "    features_downsampled,\n",
    "    target_downsampled,\n",
    "    features_valid,\n",
    "    target_valid\n",
    ")\n",
    "\n",
    "print(f'F1 наилучшей модели случайного леса на валидационной выборке: {forest_result:.4}',\n",
    "      f'Количество деревьев: {forest_est}',\n",
    "      f'Глубина дерева: {forest_depth}', sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Вывод**\n",
    "При уменьшении выборки две модели дали результат *F1-score* выше 0.59:\n",
    "- Модель дерева решений с глубиной дерева 5 - 0.6074\n",
    "- Модель случайного леса с количеством деревьев 10 и глубиной 5 - 0.5906."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Тестирование модели\n",
    "Давайте выделим четыре модели из предыдущего задания, давшие результат *F1-score* на валидационной выборке выше 0.59 и сравним их результат на тестовой выборке.\n",
    "\n",
    "Также выполним дополнительное задание и измерим значение *AUC-ROC* на тестовой выборки и сравним с *F1-score*.\n",
    "\n",
    "По окончании выполнения этой задачи сделаем выводы и выберем наиболее подходящую модель для нашей задачи."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [
    {
     "data": {
      "text/plain": "                             name  f1_score_on_valid  f1_score_on_test  \\\n0  Random Forest: class weighting             0.6197            0.6224   \n1       Random Forest: upsampling             0.6206            0.6121   \n2     Decision Tree: downsampling             0.6074            0.5931   \n3     Random Forest: downsampling             0.5906            0.5890   \n\n   auc_roc_on_test    speed  \n0           0.8537  0.02424  \n1           0.8434  0.01147  \n2           0.8229  0.00066  \n3           0.8379  0.00204  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>f1_score_on_valid</th>\n      <th>f1_score_on_test</th>\n      <th>auc_roc_on_test</th>\n      <th>speed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Random Forest: class weighting</td>\n      <td>0.6197</td>\n      <td>0.6224</td>\n      <td>0.8537</td>\n      <td>0.02424</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Random Forest: upsampling</td>\n      <td>0.6206</td>\n      <td>0.6121</td>\n      <td>0.8434</td>\n      <td>0.01147</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Decision Tree: downsampling</td>\n      <td>0.6074</td>\n      <td>0.5931</td>\n      <td>0.8229</td>\n      <td>0.00066</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Random Forest: downsampling</td>\n      <td>0.5906</td>\n      <td>0.5890</td>\n      <td>0.8379</td>\n      <td>0.00204</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\n",
    "    {\n",
    "        'name': 'Random Forest: class weighting',\n",
    "        'model': RandomForestClassifier(\n",
    "            random_state=random_state, n_estimators=70, max_depth=9, class_weight='balanced'),\n",
    "        'features': features_train,\n",
    "        'target': target_train,\n",
    "        'f1_score_on_valid': 0.6197\n",
    "    },\n",
    "    {\n",
    "        'name': 'Random Forest: upsampling',\n",
    "        'model': RandomForestClassifier(random_state=random_state, n_estimators=30, max_depth=11),\n",
    "        'features': features_upsampled,\n",
    "        'target': target_upsampled,\n",
    "        'f1_score_on_valid': 0.6206\n",
    "    },\n",
    "    {\n",
    "        'name': 'Decision Tree: downsampling',\n",
    "        'model': DecisionTreeClassifier(random_state=random_state, max_depth=5),\n",
    "        'features': features_downsampled,\n",
    "        'target': target_downsampled,\n",
    "        'f1_score_on_valid': 0.6074\n",
    "    },\n",
    "    {\n",
    "        'name': 'Random Forest: downsampling',\n",
    "        'model': RandomForestClassifier(random_state=random_state, n_estimators=10, max_depth=5),\n",
    "        'features': features_downsampled,\n",
    "        'target': target_downsampled,\n",
    "        'f1_score_on_valid': 0.5906\n",
    "    },\n",
    "]\n",
    "\n",
    "for model_obj in models:\n",
    "    model = model_obj['model']\n",
    "    model.fit(model_obj['features'], model_obj['target'])\n",
    "\n",
    "    #speed\n",
    "    start = time.time()\n",
    "    predicted_test = model.predict(features_test)\n",
    "    end = time.time()\n",
    "    speed = end - start\n",
    "\n",
    "    #f1_score\n",
    "    f1 =  f1_score(target_test, predicted_test)\n",
    "\n",
    "    #auc_roc\n",
    "    probabilities_test = model.predict_proba(features_test)\n",
    "    probabilities_one_test = probabilities_test[:, 1]\n",
    "    auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "\n",
    "    model_obj['f1_score_on_test'] = round(f1, 4)\n",
    "    model_obj['speed'] = round(speed, 5)\n",
    "    model_obj['auc_roc_on_test'] = round(auc_roc, 4)\n",
    "\n",
    "display(pd.DataFrame(models, columns=['name', 'f1_score_on_valid', 'f1_score_on_test', 'auc_roc_on_test', 'speed']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Вывод\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}